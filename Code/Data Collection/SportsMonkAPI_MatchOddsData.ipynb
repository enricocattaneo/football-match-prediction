{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Get Match Data + Odds Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *General Part - (Functions + Get all fixtures IDs)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sportmonks.soccer import SoccerApiV2\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import collections\n",
    "import time \n",
    "import pandas as pd\n",
    "import json\n",
    "# API Token \n",
    "mytoken = ''\n",
    "soccer = SoccerApiV2(api_token=mytoken)\n",
    "# Number of HTTP requests made\n",
    "print(soccer.http_requests_made)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d, parent_key='', sep='_'): \n",
    "    \"\"\"This function turns a nested dictionary into a flattened dictionary.\n",
    "    d: nested dictionary\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abbreviations of bets' types\n",
    "abbr1 = {'3WayResult': '3W', 'AsianHandicap' : 'AH', 'GoalsOver/Under': 'O/U', 'CorrectScore' : 'CS'}\n",
    "abbr2 = {'Home' : 'H', 'Away' : 'A', 'Over' : 'O', 'Under' : 'U', 'Handicap' : 'Hnd', 'Result': 'RES', 'TotalGoals': 'TG'}\n",
    "\n",
    "def myReplace(text):\n",
    "    \"\"\"This function replaces the key terms in dictionaries (abbr1 and abbr2) with the corresponding value, in order to generate a simpler and easier to understand string. \n",
    "    text: original string to simplify\n",
    "    \"\"\"\n",
    "    global abbr1, abbr2\n",
    "    for key in abbr1:\n",
    "        text = text.replace(key, abbr1[key])\n",
    "    for key in abbr2:\n",
    "        text = text.replace(key, abbr2[key])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Common Functions (Fixture and Dynamic Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_fixtures_or_dynamic(fix_ids_list, fix = True):\n",
    "    \"\"\"This function returns a list of all fixtures in fix_ids_list (a list of nested dictionaries) controlling for the API calls limit (maximum of 2000 requests for hour) by using a sleep time. In case an exception occurs during the request, the function prints a warning with the exception's type and the position of fix_ids_list at which it occurred.\n",
    "\n",
    "    fix_ids_list: list of nested dictionaries containing fixtures data\n",
    "    fix: True for match static information, False for dynamic (in-time) data\n",
    "    \"\"\"\n",
    "    complete = [] \n",
    "    exceptions = []\n",
    "    for index, i in enumerate(fix_ids_list): \n",
    "        if fix: \n",
    "            include_feat = ['localTeam', 'visitorTeam', 'referee', 'localCoach', 'visitorCoach', 'round', 'stats', 'league', 'season', 'venue'] # features for fixture\n",
    "        else:\n",
    "            include_feat = ['substitutions', 'goals', 'cards', 'corners', 'lineup', 'bench', 'sidelined'] # features for dynamic\n",
    "\n",
    "        try:\n",
    "            complete.append(flatten(soccer.fixture(fixture_id=i, includes=include_feat))) \n",
    "        except Exception as e:\n",
    "            print('************** An exception occurred: {} **************'.format(e))\n",
    "            print('************** At Index: {} **************'.format(index))\n",
    "            exceptions.append(i)\n",
    "            time.sleep(10)\n",
    "        \n",
    "        if (index + 1) % 1999 == 0: \n",
    "            print('STOP NÂ°: ', int((index+1) / 1999),' -------- PERC: ', round((index+1)/len(fix_ids_list)*100, 2), '%')\n",
    "            print('!!! WAIT ONE HOUR !!!')\n",
    "            time.sleep(3600)\n",
    "            print('--- RE-START MAKING API CALLS ---')\n",
    "    return complete, exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_exceptions_fix_dyn(complete_fix_list, exceptions_list, fix = True):\n",
    "    \"\"\"This function corrects the exceptions generated when making fixture or dynamic data requests to the API.\n",
    "    \n",
    "    complete_fix_list: list of dictionaries for the fix or dynamic data, where each dictionary contains all fixture information or dynamic events for a particular match.\n",
    "    exceptions_list: list of exceptions' indexes (in complete_fix_list)\n",
    "    fix: True for match static information, False for dynamic (in-time) data\n",
    "    \"\"\" \n",
    "    # Useful dimensions for checks\n",
    "    lenght_fix_before_correct = len(complete_fix_list)\n",
    "    lenght_exceptions = len(exceptions_list) \n",
    "    # Print check for correctness\n",
    "    print('Amount of data loss: ', lenght_exceptions)\n",
    "    \n",
    "    # In case of no exceptions\n",
    "    if not exceptions_list:\n",
    "        return complete_fix_list\n",
    "    # Specify if correction is for fixtures or dynamic data\n",
    "    if fix: \n",
    "        include_feat = ['localTeam', 'visitorTeam', 'referee', 'localCoach', 'visitorCoach', 'round', 'stats', 'league', 'season', 'venue'] \n",
    "    else:\n",
    "        include_feat = ['substitutions', 'goals', 'cards', 'corners', 'lineup', 'bench', 'sidelined']\n",
    "    # Handle exceptions\n",
    "    for e in exceptions_list:\n",
    "        complete_fix_list.append((flatten(soccer.fixture(fixture_id=e, includes=include_feat))))\n",
    "    \n",
    "    # Print check after correction\n",
    "    print('No data loss - AFTER CORRECTION? ', len(complete_fix_list) == (lenght_fix_before_correct + lenght_exceptions))\n",
    "    return complete_fix_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Odds Specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odds_ordered(unordered_data):\n",
    "    \"\"\"This function orders the unordered odds data resulting from the API in a more manageable format (list of dictionaries - where each dictionary represents a different match), excluding undesired bets' types, and giving more understandable names to  bets. \n",
    "    unordered_data: unordered odds data (in its native API format)\n",
    "    \"\"\"\n",
    "    # Not interest in all types of bets\n",
    "    bets_to_exclude = ['Goalscorer', 'Multi Scorers', 'Team Goalscorer', 'Player to be Booked', 'Player to be Sent Off']\n",
    "    final_list = []\n",
    "    for fix in range(len(unordered_data)):\n",
    "        # Create empty dictionary\n",
    "        d = {}\n",
    "        # Get match id\n",
    "        d['id'] = unordered_data[fix]['match_id'] \n",
    "        # Loop only in odds_infos value\n",
    "        for i in range(len(unordered_data[fix]['odds_infos'])): \n",
    "            # Excluding some bets' types\n",
    "            if unordered_data[fix]['odds_infos'][i]['name'] not in bets_to_exclude: \n",
    "                # Get odds_type\n",
    "                odd_name = unordered_data[fix]['odds_infos'][i]['name'].replace(' ', '') \n",
    "            # Loop for each bookmaker\n",
    "            for j in range(len(unordered_data[fix]['odds_infos'][i]['bookmaker'])): \n",
    "                # Get bookmaker name\n",
    "                bookmaker_name = unordered_data[fix]['odds_infos'][i]['bookmaker'][j]['name'].replace(' ', '')\n",
    "                \n",
    "                # Loop for each possible bet\n",
    "                for k in range(len(unordered_data[fix]['odds_infos'][i]['bookmaker'][j]['odds'])): \n",
    "                    # Create a new dictionary with only important values \n",
    "                    last_dict = unordered_data[fix]['odds_infos'][i]['bookmaker'][j]['odds'][k] \n",
    "                    # Label and value are the two fundamental values \n",
    "                    label = last_dict['label'] \n",
    "                    value = last_dict['value']\n",
    "\n",
    "                    # Consider total, handicap and extra only if they exist\n",
    "                    if 'total' in last_dict.values(): \n",
    "                        total = last_dict['total']\n",
    "                    else:\n",
    "                        total = None\n",
    "                    if 'handicap' in last_dict.values():\n",
    "                        handicap = last_dict['handicap']\n",
    "                    else:\n",
    "                        handicap = None\n",
    "                    if 'extra' in last_dict.values():\n",
    "                        extra = last_dict['extra']\n",
    "                    else:\n",
    "                        extra = None\n",
    "\n",
    "                    # Create keys' names combining all the bet main characteristics \n",
    "                    book_info = odd_name + '_' + bookmaker_name + '__' \n",
    "                    # Simplify the keys' names using myReplace()\n",
    "                    book_info = myReplace(book_info)\n",
    "\n",
    "                    # Filling the dictionary considering for the existence of different bets' types\n",
    "                    if total is None and handicap is None and extra is None: \n",
    "                        d[book_info + str(label)] = value\n",
    "                    elif total is not None and handicap is None and extra is None:\n",
    "                        d[book_info + str(label) + '_' + str(total)] = value\n",
    "                    elif total is None and handicap is not None and extra is None:\n",
    "                        d[book_info + str(label) + '_' + str(handicap)] = value\n",
    "                    elif total is None and handicap is  None and extra is not None:\n",
    "                        d[book_info + str(label) + '_' + str(extra)] = value\n",
    "                    else:\n",
    "                        d[book_info + str(label) + '_' + str(handicap) + '_' + str(total) + '_' + str(extra)] = value\n",
    "        # Append bets dictionary to list\n",
    "        final_list.append(d)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_odds(fix_ids_list):\n",
    "    \"\"\"This function returns a list of all odds in fix_ids_list (a list of nested dictionaries) controlling for the API calls limit (maximum of 2000 requests for hour) by using a sleep time. In case an exception occurs during the request, the function prints a warning with the exception's type and the position of fix_ids_list at which it occurred.\n",
    "\n",
    "    fix_ids_list: list of nested dictionaries containing odds data\n",
    "    \"\"\"    \n",
    "    complete = []\n",
    "    exceptions_index = []\n",
    "    for index, i in enumerate(fix_ids_list):\n",
    "        d = {}\n",
    "        d['match_id'] = i\n",
    "        try:\n",
    "            d['odds_infos'] = soccer.pre_match_odds(fixture_id=i)\n",
    "        except Exception as e:\n",
    "            print('************** An exception occurred: {} **************'.format(e))\n",
    "            print('************** At Index: {} **************'.format(index))\n",
    "            d['exception'] = index\n",
    "            exceptions_index.append(index)\n",
    "            time.sleep(10)\n",
    "        finally:\n",
    "            complete.append(d)\n",
    "        if (index + 1) % 1999 == 0: \n",
    "            print('STOP NÂ°: ', int((index+1) / 1999),' -------- PERC: ', round((index+1)/len(fix_ids_list)*100, 2), '%')\n",
    "            print('!!! WAIT ONE HOUR !!!')\n",
    "            time.sleep(3600)\n",
    "    return complete, exceptions_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exceptions_odds(complete_odds_list): \n",
    "    \"\"\"This function checks for the presence of exceptions or other errors in a odds list of dictionaries where each dictionary contains all odds for a particular match.\n",
    "    \n",
    "    complete_odds_list: list of dictionaries for the odds data to check\n",
    "    \"\"\"\n",
    "    print('\\nCheck for Exceptions and Errors: ')\n",
    "    exceptions_count = 0\n",
    "    for i in range(len(complete_odds_list)):\n",
    "        for k in complete_odds_list[i].keys():\n",
    "            if k not in ['match_id', 'odds_infos']:\n",
    "                print(complete_odds_list[i])\n",
    "                exceptions_count += 1\n",
    "    print('N. of detected errors: ', exceptions_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_exceptions_odds(complete_odds_list, exceptions_list):\n",
    "    \"\"\"This function corrects the exceptions generated when making odds data requests to the API.\n",
    "    \n",
    "    complete_odds_list: list of dictionaries for the odds data, where each dictionary contains all odds for a particular match.\n",
    "    exceptions_list: list of exceptions' indexes (in complete_odds_list)\n",
    "    \"\"\"  \n",
    "    # Check for exceptions before   \n",
    "    check_exceptions_odds(complete_odds_list)\n",
    "    # In case there are no exceptions no necessity to correct and a 2nd check \n",
    "    if not exceptions_list:\n",
    "        return complete_odds_list\n",
    "    \n",
    "    # Handle exceptions\n",
    "    for e in exceptions_list:\n",
    "        # Delete exception key and value\n",
    "        complete_odds_list[e].pop('exception', None)\n",
    "        # Make a new request to the API to get only the data with an exception\n",
    "        complete_odds_list[e]['odds_infos'] = soccer.pre_match_odds(fixture_id = complete_odds_list[e]['match_id'])\n",
    "    # Check for exceptions after\n",
    "    check_exceptions_odds(complete_odds_list)\n",
    "    return complete_odds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_inJSON(complete_odds_list, file_path):\n",
    "    \"\"\"This function stores, after ordering and correcting its format, complete_odds_list as a JSON file. It also provides a quick check of the process.\n",
    "    \n",
    "    complete_odds_list: list of dictionaries for the odds data, where each dictionary contains all odds for a particular match.\n",
    "    file_path: path where to store data as JSON file\n",
    "    \"\"\"  \n",
    "    # Ordering Data\n",
    "    final_odds = odds_ordered(complete_odds_list)\n",
    "\n",
    "    # After a check, store data as a JSON file\n",
    "    if len(final_odds) == len(complete_odds_list):\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_odds, f, ensure_ascii=False, indent=4)\n",
    "        f.close()\n",
    "        print('Correctly Stored!!!')\n",
    "    else: \n",
    "        print('Error occurred in the ordering process - Data not stored!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get All Fixtures IDs for each League & Cup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify end day for API requests \n",
    "end_day = '2022-04-22'\n",
    "# Empty dictionaries to store cups and leagues fixture data from API\n",
    "cups_fix_dict = dict()\n",
    "leagues_fix_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To obtain the wanted fixtures, need to specify start date, end date (end_day), and the league_ids. Then store them in the previously created dictionaries giving each competition a different name.\n",
    "\n",
    "# CHAMPIONS LEAGUE \n",
    "cups_fix_dict['cl_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 2) \n",
    "# EUROPA LEAGUE\n",
    "cups_fix_dict['el_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 5)\n",
    "# PREMIER LEAGUE \n",
    "leagues_fix_dict['pl_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 8)\n",
    "# FA CUP\n",
    "cups_fix_dict['fa_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 24)\n",
    "# BUNDESLIGA \n",
    "leagues_fix_dict['bu_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 82)\n",
    "# LIGUE 1 \n",
    "leagues_fix_dict['l1_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 301)\n",
    "# SERIE A \n",
    "leagues_fix_dict['sa_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 384)\n",
    "# COPPA ITALIA\n",
    "cups_fix_dict['ci_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 390)\n",
    "# LA LIGA\n",
    "leagues_fix_dict['ll_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 564)\n",
    "# COPA DEL REY \n",
    "cups_fix_dict['dr_fixtures'] = soccer.fixtures(start_date = '2011-08-01', end_date = end_day, league_ids = 570)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty lists to reorganize and store fixtures observations\n",
    "cups_all_fixtures = []\n",
    "leagues_all_fixtures = []\n",
    "# Create a list of dictionaries for cups' fixtures \n",
    "for cupvalues in cups_fix_dict.values():\n",
    "    for fix in cupvalues:\n",
    "        cups_all_fixtures.append(fix['id'])\n",
    "# Create a list of dictionaries for leagues' fixtures     \n",
    "for leaguevalues in leagues_fix_dict.values():\n",
    "    for fix in leaguevalues:\n",
    "        leagues_all_fixtures.append(fix['id'])\n",
    "\n",
    "# Check the length of both lists\n",
    "print('N. of fixtures observed for CUPS: ', len(cups_all_fixtures))\n",
    "print('N. of fixtures observed for LEAGUES: ', len(leagues_all_fixtures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Match Data* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leagues Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3600)\n",
    "# Get fixtures data for leagues games\n",
    "leagues_complete, exceptions_leagues_complete = list_fixtures_or_dynamic(leagues_all_fixtures, fix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction of exceptions (if necessary)\n",
    "leagues_complete = correct_exceptions_fix_dyn(complete_fix_list=leagues_complete, exceptions_list=exceptions_leagues_complete)\n",
    "\n",
    "# Store leagues data as CSV\n",
    "leagues = pd.DataFrame(leagues_complete)\n",
    "leagues.to_csv(\"../../Data/From_Collection/Match&Odds/leagues_static.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cups Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3600) \n",
    "# Get fixtures data for cups games\n",
    "cups_complete, exceptions_cups_complete = list_fixtures_or_dynamic(cups_all_fixtures, fix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction of exception (if necessary)\n",
    "cups_complete = correct_exceptions_fix_dyn(complete_fix_list=cups_complete, exceptions_list=exceptions_cups_complete)\n",
    "\n",
    "# Store cups data as CSV\n",
    "cups = pd.DataFrame(cups_complete)\n",
    "cups.to_csv(\"../../Data/From_Collection/Match&Odds/cups_static.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Odds Data* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leagues Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3600)\n",
    "# Acquire data from API\n",
    "leagues_complete_odds, exceptions_leagues_odds = list_all_odds(leagues_all_fixtures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle exceptions from previous step\n",
    "leagues_complete_odds = correct_exceptions_odds(complete_odds_list=leagues_complete_odds, exceptions_list=exceptions_leagues_odds)\n",
    "# Store data\n",
    "store_inJSON(complete_odds_list=leagues_complete_odds, file_path='../../Data/From_Collection/Match&Odds/leagues_odds.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cups Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3600)\n",
    "cups_complete_odds, exceptions_cups_odds = list_all_odds(cups_all_fixtures) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle exceptions from previous step\n",
    "cups_complete_odds = correct_exceptions_odds(complete_odds_list=cups_complete_odds, exceptions_list=exceptions_cups_odds)\n",
    "# Store data\n",
    "store_inJSON(complete_odds_list=cups_complete_odds, file_path='../../Data/From_Collection/Match&Odds/cups_odds.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *More Features Data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leagues More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3600)\n",
    "leagues_more, exceptions_leagues_more = list_fixtures_or_dynamic(leagues_all_fixtures, fix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction of exceptions (if necessary)\n",
    "leagues_more = correct_exceptions_fix_dyn(complete_fix_list=leagues_more, exceptions_list=exceptions_leagues_more, fix=False)\n",
    "\n",
    "# Store cups data as CSV\n",
    "leagues = pd.DataFrame(leagues_more)\n",
    "leagues.to_csv(\"../../Data/From_Collection/Match&Odds/leagues_more.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cups More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3600)\n",
    "cups_more, exceptions_cups_more = list_fixtures_or_dynamic(cups_all_fixtures, fix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction of exceptions (if necessary)\n",
    "cups_more = correct_exceptions_fix_dyn(complete_fix_list=cups_more, exceptions_list=exceptions_cups_more, fix=False)\n",
    "\n",
    "# Store cups data as CSV\n",
    "cups = pd.DataFrame(cups_more)\n",
    "cups.to_csv(\"../../Data/From_Collection/Match&Odds/cups_more.csv\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "73df3d2a648ddfe6e132dd0b2981f8c5ee01eb57f65aaa52301d101a94b0ebb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
